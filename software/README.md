# MLonMCU Hand Gesture Classification Project

A PyTorch-based deep learning project for hand gesture classification on the HAGRID dataset, designed for autonomous vehicle control.

## ğŸ¯ Project Overview

This project trains a Convolutional Neural Network (CNN) to classify 6 hand gestures that map to vehicle control commands:

| Gesture | Class ID | Control Command |
|---------|----------|-----------------|
| palm    | 0        | STOP |
| rock    | 1        | DRIVE FORWARD STRAIGHT |
| pinkie  | 2        | STEER FORWARD RIGHT |
| one     | 3        | STEER FORWARD LEFT |
| fist    | 4        | DRIVE BACKWARD STRAIGHT |
| others  | 5        | OTHER/background |

## ğŸ“ Project Structure

changed! write new structure TO DO

<!-- ```
MLonMCU_proj/
â”œâ”€â”€ config.yaml              # All hyperparameters and settings
â”œâ”€â”€ main.py                  # Main training orchestrator
â”œâ”€â”€ requirements.txt         # Python dependencies
â”œâ”€â”€ datasets/                # Dataset directory
â”‚   â””â”€â”€ hagrid_balanced_classification/
â”‚       â”œâ”€â”€ train/          # Training images (by class)
â”‚       â”œâ”€â”€ val/            # Validation images (by class)
â”‚       â””â”€â”€ test/           # Test images (by class)
â”œâ”€â”€ src/                     # Source code modules
â”‚   â”œâ”€â”€ data.py             # Dataset loading, transforms, dataloaders
â”‚   â”œâ”€â”€ model.py            # CNN architecture (BaselineCNN)
â”‚   â”œâ”€â”€ engine.py           # Training & evaluation loops
â”‚   â”œâ”€â”€ checkpoint.py       # Model checkpoint management
â”‚   â”œâ”€â”€ metrics.py          # CSV logging for metrics
â”‚   â”œâ”€â”€ per_class_metrics.py # Confusion matrix & per-class metrics
â”‚   â”œâ”€â”€ config.py           # Config validation
â”‚   â”œâ”€â”€ run.py              # Run directory management
â”‚   â”œâ”€â”€ model_utils.py      # Model summary generation
â”‚   â””â”€â”€ viz.py              # Visualization utilities
â””â”€â”€ runs/                    # Training outputs
    â””â”€â”€ <run_name>-<timestamp>/
        â”œâ”€â”€ config_snapshot.yaml
        â”œâ”€â”€ model_summary.txt
        â”œâ”€â”€ checkpoints/
        â”‚   â””â”€â”€ best.pt
        â””â”€â”€ logs/
            â”œâ”€â”€ metrics.csv
            â”œâ”€â”€ confusion_matrix.csv
            â”œâ”€â”€ per_class_metrics.csv
            â””â”€â”€ transform_preview_train.png
``` -->

## ğŸš€ Quick Start

### Installation

```bash
# Clone repository
git clone <repository_url>
cd MLonMCU_proj

# Install dependencies
pip install -r requirements.txt
```

### Training

**Start new training:**
```bash
python main.py --name baseline128
```

**Resume from checkpoint:**
```bash
python main.py --name baseline128_continued --checkpoint baseline128-20260222-123456
```

### Configuration

Edit `config.yaml` to customize:
- Image size: `data.input_size` (default: 128)
- Batch size: `train.batch_size` (default: 512)
- Learning rate: `train.lr` (default: 3e-3)
- Epochs: `train.epochs` (default: 1000)
- Model architecture: `model.channels` (default: [16, 32, 64, 128])

## ğŸ—ï¸ Model Architecture

**BaselineCNN** - 4-stage CNN with global average pooling:

```
Input: [B, 1, 128, 128]  (grayscale images)
  â†“
Stage 1: Conv(1â†’16) â†’ Conv(16â†’16) â†’ MaxPool â†’ [B, 16, 64, 64]
  â†“
Stage 2: Conv(16â†’32) â†’ Conv(32â†’32) â†’ MaxPool â†’ [B, 32, 32, 32]
  â†“
Stage 3: Conv(32â†’64) â†’ Conv(64â†’64) â†’ MaxPool â†’ [B, 64, 16, 16]
  â†“
Stage 4: Conv(64â†’128) â†’ Conv(128â†’128) â†’ MaxPool â†’ [B, 128, 8, 8]
  â†“
Global Average Pooling â†’ [B, 128]
  â†“
Linear(128 â†’ 6) â†’ [B, 6] logits
```

**Total Parameters:** ~294K

## ğŸ“Š Training Pipeline

1. **Data Loading**
   - Letterbox resize to 128Ã—128
   - Convert to grayscale
   - Normalize to mean=0.5, std=0.5
   - DataLoader with batch_size=512, num_workers=8

2. **Training Loop** (30 epochs)
   - Forward pass through CNN
   - CrossEntropyLoss
   - Adam optimizer (lr=3e-3)
   - Save best model based on validation accuracy

3. **Evaluation**
   - Validation set evaluation after each epoch
   - Confusion matrix on best checkpoint
   - Per-class precision, recall, F1-score

4. **Outputs** (saved to `runs/<run_name>/`)
   - `checkpoints/best.pt` - Best model weights
   - `logs/metrics.csv` - Training/validation metrics
   - `logs/confusion_matrix.csv` - Confusion matrix
   - `logs/per_class_metrics.csv` - Per-class metrics

## ğŸ”§ Key Features Added

### âœ… Device Management
- Centralized device setup (CPU/CUDA)
- Automatic device placement for all operations
- No more device mismatch errors

### âœ… Checkpoint Resume
- Resume training from previous runs
- Preserves optimizer state and best accuracy
- `--checkpoint` argument for easy resumption

### âœ… Class Distribution Debugging
- Prints class distribution for train/val sets
- Detects class imbalance issues
- Debug stats for batch statistics

### âœ… Comprehensive Metrics
- Per-epoch CSV logging
- Confusion matrix visualization
- Per-class precision/recall/F1

### âœ… GPU Optimization
- Increased batch size to 512 for better GPU utilization
- Optimized num_workers (8) for balanced I/O
- Mixed precision training ready

## ğŸ“ˆ Monitoring Training

During training, you'll see:
```
epoch 01/1000 | TRAIN: loss 1.7925, acc 0.167 | VAL: loss 1.7922, acc 0.167
 ->  new best: val acc 0.167
```

Check metrics in `runs/<run_name>/logs/metrics.csv`:
```csv
epoch,train_loss,train_acc,val_loss,val_acc
1,1.7925,0.167,1.7922,0.167
2,1.7924,0.167,1.7921,0.167
...
```

## ğŸ› Troubleshooting

**Low accuracy (stuck at ~16.7%)**
- Enable normalization in config.yaml
- Check class distribution with debug prints
- Verify dataset is correctly loaded

**GPU not utilized**
- Increase batch_size in config.yaml
- Check with `nvidia-smi`
- Ensure CUDA is available

**Out of memory**
- Reduce batch_size
- Reduce input_size
- Reduce model channels

## ğŸ“ Notes

- Test set evaluation is commented out by default to prevent data leakage during development
- Uncomment test evaluation in `main.py` when ready for final evaluation
- Debug image previews are saved if `debug.plot_images: true`

## ğŸ¤ Contributing

This project was developed for ML on MCU applications with emphasis on:
- Efficient model architecture (small parameter count)
- Clean, modular codebase
- Comprehensive logging and debugging

## ğŸ“„ License

[Add your license here]
```
