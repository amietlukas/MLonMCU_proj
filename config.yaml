# config.yaml
# here we set all the parameters.
seed: 42

data:
  dataset_root: datasets/HAGRID/hagrid_full
  input_size: 128 # the grayscale images are resized to 128x128
  num_classes: 6

preprocess:
  type: letterbox        # may add different methods in future
  fill: 0                # padding value for letterbox
  normalize:
    mean: 0.5
    std: 0.5

train:
  batch_size: 256        # Increased from 128 for better GPU utilization
  num_workers: 8         # Reduced from 32 for balanced I/O
  shuffle: true
  max_train_batches: 2 # set to a int for quicker testing, set to null for full training
  max_val_batches: null # set to a int for quicker testing, set to null for full validation
  epochs: 150
  

model:
  type: baseline_cnn
  in_channels: 3 # 1 = grayscale, 3 = RGB
  num_classes: 6 # match data.num_classes!

  # stages define channel widths after each downsampling
  channels: [16, 32, 64, 128]
  # convs per stage (1 = Conv-ReLU-Pool, 2 = Conv-ReLU-Conv-ReLU-Pool)
  blocks_per_stage: 2
  kernel_size: 3

debug:
  verbose: false # set to true to see all [DEBUG] and [INFO] prints
  # TODO: can't plot RGB -> set to false
  # can't plot if in_channels=3!
  plot_images: false # set false to disable plotting images during training
  n_plot_per_class: 5

# currently implemented:
# "CosineAnnealingLR"
LR_scheduler:
  type: CosineAnnealingLR
  lr: 3e-3
  # for CosineAnnealingLR:
  eta_min: 1e-5 

early_stopping:
  enabled: true
  patience: 50 # stop if no improvement in validation loss for 10 epochs
  min_delta: 1e-4 # dont count noise as improvement TODO: find noise level